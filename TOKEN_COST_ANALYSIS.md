# üîç An√°lise de Custos de Tokens de Entrada (Input Tokens)

## üìã Resumo Executivo

Esta an√°lise identifica os principais motivos para alto custo de tokens de entrada no sistema Nexus Financial Analyst e prop√µe solu√ß√µes pr√°ticas para otimiza√ß√£o.

## üéØ Principais Causas Identificadas

### 1. **Prompt do Sistema Muito Extenso** (CR√çTICO)
**Localiza√ß√£o**: `/backend/prompt.toml`

**Problema**:
- Tamanho: 3,328 bytes (~830 tokens)
- Enviado em **TODA** requisi√ß√£o ao LLM
- Cont√©m instru√ß√µes detalhadas de workflows, regras de UI, e compliance

**Impacto Estimado**:
```
Custo por requisi√ß√£o (gpt-4o-mini):
830 tokens √ó $0.150/1M tokens = $0.0001245 por mensagem
Para 10,000 mensagens/m√™s = $1.245 s√≥ do prompt do sistema
```

**Solu√ß√£o Proposta**:
- Reduzir prompt para instru√ß√µes essenciais (~300 tokens)
- Mover detalhes de UI/workflow para documenta√ß√£o separada
- Usar "few-shot examples" em vez de instru√ß√µes longas
- Considerar usar system fingerprinting/caching (se dispon√≠vel no modelo)

---

### 2. **Ferramentas Retornam Dados N√£o Filtrados** (ALTO)
**Localiza√ß√£o**: `/backend/tools.py`

**Problemas Espec√≠ficos**:

#### a) `get_historical_stock_price()` (Linha 39-52)
```python
def get_historical_stock_price(ticker:str, start_date: str, end_date:str):
    stock = yf.Ticker(ticker)
    return stock.history(start=start_date, end=end_date).to_dict()
```

**Problema**:
- Retorna DataFrame completo convertido para dicion√°rio
- Para 1 ano de dados: ~252 dias √∫teis √ó m√∫ltiplas colunas (Open, High, Low, Close, Volume)
- Tamanho estimado: 15,000-30,000 tokens para 1 ano de dados

**Exemplo de Sa√≠da**:
```json
{
  "Open": {"2024-01-01": 150.23, "2024-01-02": 151.45, ...},
  "High": {"2024-01-01": 152.67, "2024-01-02": 153.89, ...},
  "Low": {"2024-01-01": 149.12, "2024-01-02": 150.34, ...},
  "Close": {"2024-01-01": 151.78, "2024-01-02": 152.90, ...},
  "Volume": {"2024-01-01": 45678900, "2024-01-02": 56789012, ...}
}
```

#### b) `get_balance_sheet()` (Linha 55-69)
```python
def get_balance_sheet(ticker: str):
    stock = yf.Ticker(ticker)
    return stock.balance_sheet
```

**Problema**:
- Retorna DataFrame completo com todas as linhas do balan√ßo
- Cont√©m 50-100+ linhas de dados financeiros
- M√∫ltiplos per√≠odos (geralmente 4 trimestres)
- Tamanho estimado: 5,000-15,000 tokens

**Exemplo de Dados**:
```
                                2024-09-30  2024-06-30  2024-03-31  2023-12-31
Total Assets                     365000000   358000000   351000000   345000000
Current Assets                   145000000   142000000   139000000   136000000
Cash And Cash Equivalents         78000000    76000000    74000000    72000000
...
(50-100+ linhas adicionais)
```

#### c) `get_stock_news()` (Linha 74-87)
```python
def get_stock_news(ticker: str):
    stock = yf.Ticker(ticker)
    return stock.news
```

**Problema**:
- Retorna lista completa de not√≠cias (geralmente 10-50 artigos)
- Cada artigo cont√©m: t√≠tulo, descri√ß√£o, conte√∫do, publisher, etc.
- Tamanho estimado: 3,000-10,000 tokens por consulta

#### d) `web_search()` (Linha 91-104)
```python
def web_search(query: str):
    tavily_client = TavilyClient()
    return tavily_client.search(query)
```

**Problema**:
- Retorna resultados completos da Tavily API
- Pode incluir m√∫ltiplos artigos com conte√∫do completo
- Tamanho vari√°vel: 2,000-15,000 tokens dependendo da consulta

---

### 3. **Sem Gerenciamento de Hist√≥rico de Conversa√ß√£o** (M√âDIO)
**Localiza√ß√£o**: `/backend/main.py` (Linha 90-93)

**Problema**:
```python
messages = [
    SystemMessage(content=system_message),  # ~830 tokens
    HumanMessage(content=request.prompt.content)
]
```

**Quest√µes**:
- N√£o h√° limite de tamanho para o hist√≥rico
- `InMemorySaver` mant√©m todo o hist√≥rico da thread
- Conversas longas podem acumular 10,000+ tokens
- Cada nova mensagem inclui todo o contexto anterior

**Impacto**:
- Thread com 10 intera√ß√µes = potencialmente 50,000+ tokens acumulados
- Custo cresce linearmente com o comprimento da conversa

---

### 4. **Sem Monitoramento de Uso de Tokens** (M√âDIO)
**Localiza√ß√£o**: Todo o sistema

**Problema**:
- Nenhum logging de tokens consumidos
- Imposs√≠vel identificar quais ferramentas consomem mais tokens
- Sem m√©tricas para otimiza√ß√£o baseada em dados
- Sem alertas para uso excessivo

---

### 5. **Configura√ß√£o do Modelo Sem Otimiza√ß√µes** (BAIXO)
**Localiza√ß√£o**: `/backend/agent.py` (Linha 44-47)

**Problema**:
```python
model = ChatOpenAI(
    model = os.getenv('LLM_NAME', ""),
    base_url = os.getenv('LLM_BASE_URL',"")
)
```

**Quest√µes**:
- Sem configura√ß√£o de `max_tokens` para limitar respostas
- Sem `temperature` configurada (pode gerar respostas mais longas)
- Sem configura√ß√£o de streaming otimizado

---

## üí° Solu√ß√µes Recomendadas (Prioridade Alta ‚Üí Baixa)

### üî¥ PRIORIDADE 1: Otimizar Sa√≠da das Ferramentas

#### Solu√ß√£o 1.1: Resumir Dados Hist√≥ricos
```python
@tool("get_historical_stock_price", 
      description="Returns summarized historical stock price data")
def get_historical_stock_price(ticker: str, start_date: str, end_date: str):
    logger.info(f"Fetching historical stock price for ticker: {ticker}")
    stock = yf.Ticker(ticker)
    df = stock.history(start=start_date, end=end_date)
    
    # Retornar apenas resumo estat√≠stico + amostragem
    return {
        "ticker": ticker,
        "period": f"{start_date} to {end_date}",
        "summary": {
            "start_price": float(df['Close'].iloc[0]),
            "end_price": float(df['Close'].iloc[-1]),
            "high": float(df['High'].max()),
            "low": float(df['Low'].min()),
            "avg_volume": int(df['Volume'].mean()),
            "total_return_pct": float((df['Close'].iloc[-1] / df['Close'].iloc[0] - 1) * 100)
        },
        "monthly_closes": df['Close'].resample('M').last().to_dict(),
        "data_points": len(df)
    }
```
**Economia**: ~90% de tokens (de 15,000 para ~1,500 tokens)

#### Solu√ß√£o 1.2: Filtrar Balance Sheet
```python
@tool("get_balance_sheet", 
      description="Returns key balance sheet metrics")
def get_balance_sheet(ticker: str):
    logger.info(f"Fetching balance sheet for ticker: {ticker}")
    stock = yf.Ticker(ticker)
    bs = stock.balance_sheet
    
    # Retornar apenas m√©tricas chave
    key_metrics = [
        'Total Assets',
        'Current Assets', 
        'Cash And Cash Equivalents',
        'Total Liabilities Net Minority Interest',
        'Current Liabilities',
        'Total Debt',
        'Stockholders Equity'
    ]
    
    # Filtrar e pegar apenas √∫ltimo per√≠odo
    latest = bs.iloc[:, 0] if not bs.empty else {}
    filtered = {k: latest.get(k) for k in key_metrics if k in latest}
    
    return {
        "ticker": ticker,
        "date": bs.columns[0].strftime('%Y-%m-%d') if not bs.empty else None,
        "metrics": filtered,
        "currency": "USD"
    }
```
**Economia**: ~85% de tokens (de 10,000 para ~1,500 tokens)

#### Solu√ß√£o 1.3: Limitar Not√≠cias
```python
@tool("get_stock_news",
      description="Returns recent news headlines (last 5 articles)")
def get_stock_news(ticker: str):
    logger.info(f"Fetching news for ticker: {ticker}")
    stock = yf.Ticker(ticker)
    news = stock.news[:5]  # Limitar a 5 artigos
    
    # Retornar apenas informa√ß√µes essenciais
    return [
        {
            "title": article.get("title", ""),
            "publisher": article.get("publisher", ""),
            "link": article.get("link", ""),
            "published": article.get("providerPublishTime", "")
        }
        for article in news
    ]
```
**Economia**: ~70% de tokens (de 8,000 para ~2,400 tokens)

---

### üü° PRIORIDADE 2: Comprimir Prompt do Sistema

#### Solu√ß√£o 2.1: Vers√£o Compacta do Prompt
```toml
prompt = """
[ROLE]
You are a professional financial analyst assistant. Analyze stocks, provide market briefings, and compare tickers. Always cite sources and include disclaimers.

[WORKFLOWS]
1. Stock Analyzer: Price ‚Üí History (1Y) ‚Üí Financials ‚Üí News
2. Market Pulse: Watchlist ‚Üí Movers ‚Üí Macro Headlines  
3. Stock Showdown: Compare 2-4 tickers side-by-side

[OUTPUT FORMAT]
1. Summary (bullets)
2. Visual/Tables
3. Analysis narrative
4. Sources (publisher + date)
5. 2-3 follow-up questions

[COMPLIANCE]
- "Not financial advice" disclaimer
- Neutral, data-driven tone
- State data limitations
- Cite all sources

[CHARTS]
<2w: hourly/daily | 1-3M: daily | 6M-2Y: daily/weekly | >2Y: weekly/monthly
Always label axes and state date range.
"""
```
**Economia**: ~65% de tokens (de 830 para ~290 tokens)

---

### üü¢ PRIORIDADE 3: Gerenciar Hist√≥rico de Conversa√ß√£o

#### Solu√ß√£o 3.1: Implementar Janela Deslizante
```python
from langchain.memory import ConversationBufferWindowMemory

# Manter apenas √∫ltimas 10 mensagens
memory = ConversationBufferWindowMemory(k=10, return_messages=True)
```

#### Solu√ß√£o 3.2: Resumir Conversas Longas
```python
from langchain.memory import ConversationSummaryMemory

# Resumir automaticamente ap√≥s N mensagens
memory = ConversationSummaryMemory(
    llm=model,
    max_token_limit=2000,
    return_messages=True
)
```
**Economia**: ~50-80% em conversas longas

---

### üîµ PRIORIDADE 4: Adicionar Monitoramento de Tokens

#### Solu√ß√£o 4.1: Logging de Uso de Tokens
```python
from langchain.callbacks import get_openai_callback

@app.post('/api/chat')
async def chat(request: RequestObject):
    with get_openai_callback() as cb:
        # ... processo existente ...
        
        logger.info(f"Token usage - Input: {cb.prompt_tokens}, "
                   f"Output: {cb.completion_tokens}, "
                   f"Total: {cb.total_tokens}, "
                   f"Cost: ${cb.total_cost:.4f}")
```

#### Solu√ß√£o 4.2: M√©tricas Prometheus (Opcional)
```python
from prometheus_client import Counter, Histogram

token_counter = Counter('llm_tokens_total', 'Total tokens used', ['type'])
token_cost = Histogram('llm_cost_dollars', 'Cost per request')

# No c√≥digo:
token_counter.labels(type='input').inc(cb.prompt_tokens)
token_counter.labels(type='output').inc(cb.completion_tokens)
token_cost.observe(cb.total_cost)
```

---

### üü£ PRIORIDADE 5: Otimiza√ß√µes de Modelo

```python
model = ChatOpenAI(
    model=os.getenv('LLM_NAME', "gpt-4o-mini"),
    base_url=os.getenv('LLM_BASE_URL', ""),
    max_tokens=2000,  # Limitar resposta
    temperature=0.3,   # Respostas mais concisas e focadas
    streaming=True     # J√° implementado
)
```

---

## üìä Impacto Estimado das Otimiza√ß√µes

| Otimiza√ß√£o | Economia de Tokens | Impacto no Custo | Dificuldade |
|------------|-------------------|------------------|-------------|
| Resumir dados hist√≥ricos | 12,000 tokens/req | -70% | Baixa |
| Filtrar balance sheet | 8,000 tokens/req | -60% | Baixa |
| Limitar not√≠cias | 5,000 tokens/req | -50% | Baixa |
| Comprimir prompt sistema | 500 tokens/req | -65% | M√©dia |
| Gerenciar hist√≥rico | 10,000+ tokens/thread | -60% | M√©dia |
| **TOTAL ESTIMADO** | **~35,000 tokens/req** | **~70% redu√ß√£o** | - |

### Exemplo de Economia Mensal (10,000 requisi√ß√µes):

**Antes das otimiza√ß√µes:**
```
M√©dia: ~50,000 tokens/requisi√ß√£o
10,000 req √ó 50,000 tokens = 500M tokens/m√™s
Custo (gpt-4o-mini): $75/m√™s
```

**Ap√≥s otimiza√ß√µes:**
```
M√©dia: ~15,000 tokens/requisi√ß√£o  
10,000 req √ó 15,000 tokens = 150M tokens/m√™s
Custo (gpt-4o-mini): $22.50/m√™s
**Economia: $52.50/m√™s (70%)**
```

---

## üéØ Plano de Implementa√ß√£o Recomendado

### Fase 1 (Impacto Imediato - 1-2 dias)
1. ‚úÖ Otimizar `get_historical_stock_price()` 
2. ‚úÖ Otimizar `get_balance_sheet()`
3. ‚úÖ Otimizar `get_stock_news()`
4. ‚úÖ Adicionar logging de tokens

### Fase 2 (Impacto Alto - 2-3 dias)
5. ‚úÖ Comprimir prompt do sistema
6. ‚úÖ Implementar gerenciamento de hist√≥rico
7. ‚úÖ Adicionar configura√ß√µes de modelo

### Fase 3 (Monitoramento - 1 dia)
8. ‚úÖ Dashboard de m√©tricas (opcional)
9. ‚úÖ Alertas de uso excessivo (opcional)
10. ‚úÖ Documenta√ß√£o de best practices

---

## üìö Recursos Adicionais

### Ferramentas de An√°lise de Tokens
- [OpenAI Tokenizer](https://platform.openai.com/tokenizer)
- [tiktoken](https://github.com/openai/tiktoken) - Biblioteca Python oficial

### Documenta√ß√£o Relevante
- [LangChain Token Counting](https://python.langchain.com/docs/how_to/token_counting/)
- [OpenAI Token Optimization](https://platform.openai.com/docs/guides/optimization)
- [LangSmith Monitoring](https://docs.smith.langchain.com/)

---

## üèÅ Conclus√£o

As principais causas do alto custo de tokens de entrada s√£o:

1. **Ferramentas que retornam dados completos n√£o processados** (70% do problema)
2. **Prompt do sistema muito extenso** (15% do problema)  
3. **Falta de gerenciamento de hist√≥rico** (10% do problema)
4. **Falta de monitoramento** (5% do problema - impede otimiza√ß√£o)

Implementando as solu√ß√µes da **Fase 1** pode-se obter **~70% de redu√ß√£o** nos custos de tokens com **esfor√ßo relativamente baixo** (1-2 dias de desenvolvimento).

---

**Data da An√°lise**: 28 de Dezembro de 2024  
**Vers√£o**: 1.0  
**Status**: ‚úÖ An√°lise Completa - Aguardando Implementa√ß√£o
